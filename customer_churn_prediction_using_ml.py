# -*- coding: utf-8 -*-
"""Customer Churn Prediction using ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C1ioT1lKColSRHu6mmyK0plnXqAqjpjL

**1. Importing the Dependencies**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pickle

"""**2. Data Loading and Understanding**"""

# Load tech csv data into pandas dataframe
df = pd.read_csv("/content/WA_Fn-UseC_-Telco-Customer-Churn.csv")

df.shape

df.head()

df.info()

# Dropping customerId column as this is not required for modelling
df = df.drop(columns= ['customerID'])

df.head(2)

print(df["gender"].unique())

# printing the unique values in all the columns

numerical_features_list= ["tenure", "MonthlyCharges", "TotalCharges"]

for col in df.columns:
    if col not in numerical_features_list:
      print(col,df[col].unique())
      print("-"*50)

# finding missing values in the columns
df.isnull().sum()

# We found an error since there's a missing value ' '
#df["TotalCharges"]=df["TotalCharges"].astype(float)

# 11 Empty values for TotalCharges
df[df["TotalCharges"]==' ']

df["TotalCharges"]=df["TotalCharges"].replace({" " : "0.0"})

df["TotalCharges"]=df["TotalCharges"].astype(float)

df.info()

# checking the class distribution of target column
print(df["Churn"].value_counts())

"""**Insights:**

1. Customer ID removed as it is not required for modelling
2. No missing values in the dataset
3. Missing values in the TotalCharges column were replaced with 0
4. Class imbalance identified in the target column

**3. Exploratory Data Analysis (EDA)**
"""

df.shape

df.columns

df.head(2)

df.describe()

"""**Numerical Features - Analysis**

Understand the distribution of the numerical features
"""

def plot_histogram(df, column_name):
  plt.figure(figsize=(5, 3))
  sns.histplot(df[column_name], kde=True)
  plt.title(f"Distribution of {column_name}")

  # calculate the mean and median values for the columns
  col_mean = df[column_name].mean()
  col_median= df[column_name].median()

  # add vertical lines for mean and median
  plt.axvline(col_mean, color="red", linestyle="--", label="Mean")
  plt.axvline(col_median, color="green", linestyle="--", label="Median")

  plt.legend()
  plt.show()

plot_histogram(df, "tenure")

plot_histogram(df, "MonthlyCharges")

plot_histogram(df, "TotalCharges")

"""Box plot for numerical features"""

def plot_boxplot(df, column_name):

  plt.figure(figsize=(5,3))
  sns.boxplot(y=df[column_name])
  plt.title(f"Distribution of {column_name}")
  plt.ylabel(column_name)
  plt.show()

plot_boxplot(df, "tenure")

plot_boxplot(df,"MonthlyCharges")

plot_boxplot(df,"TotalCharges")

"""**Correlation Heatmap for numerical columns**"""

# correlation matrix - heatmap

plt.figure(figsize=(8,4))
sns.heatmap(df[["tenure", "MonthlyCharges", "TotalCharges"]].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

"""Categorical features - Analysis"""

df.columns

df.info()

object_cols=df.select_dtypes(include="object").columns.to_list()

object_cols=["SeniorCitizen"] + object_cols

for col in object_cols:
  plt.figure(figsize=(5,3))
  sns.countplot(x=df[col])
  plt.title(f"Count Plot of {col}")
  plt.show()

"""Working on the imbalance in the target(churn) column

**4. Data Preprocessing**

Label encoding of target column
"""

df["Churn"]= df["Churn"].replace({"Yes":1, "No": 0})

df.head()

print(df["Churn"].value_counts())

"""Label encoding of categorical features"""

# identifying columns with object data types
object_columns= df.select_dtypes(include="object").columns

print(object_columns)

# initialise a dictionary to save the encoders

encoders= {}

# apply label encoding and store the encoders

for column in object_columns:
  label_encoder = LabelEncoder()
  df[column]= label_encoder.fit_transform(df[column])
  encoders[column]= label_encoder

# save the encoders to a pickle file

with open("encoders.pkl", "wb") as f:
  pickle.dump(encoders, f)

encoders

df.head(4)

"""**Training and Test Data Split**"""

# splitting the features and target

X = df.drop(columns=["Churn"])
Y = df["Churn"]

print(X)

print(Y)

# split training and test data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.2, random_state=42)

print(Y_train.shape)

print(Y_train.value_counts())

"""**SMOTE (Sythetic minority oversampling technique)**"""

smote=SMOTE(random_state=42)

X_train_smote, Y_train_smote = smote.fit_resample(X_train, Y_train)

print(Y_train_smote.shape)

print(Y_train_smote.value_counts())

"""**5. Model Training**

Training with default hyperparameters
"""

# dictionary of models

models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random forest": RandomForestClassifier(random_state=42),
    "XGBoost": XGBClassifier(random_state=42)
}

# using manual cross validation for XGBoost and automatic cross validation for other two models

cv_scores = {}

# Define StratifiedKFold for manual cross-validation (used only for XGBoost)
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)


for model_name, model in models.items():
    print(f"Training {model_name} with default parameters")

    if model_name == "XGBoost":
        # Manual cross-validation for XGBoost
        fold_scores = []

        for train_idx, test_idx in kf.split(X_train_smote, Y_train_smote):
            X_train_fold, X_test_fold = X_train_smote.iloc[train_idx], X_train_smote.iloc[test_idx]
            Y_train_fold, Y_test_fold = Y_train_smote.iloc[train_idx], Y_train_smote.iloc[test_idx]

            model.fit(X_train_fold, Y_train_fold)  # Fit model on the training fold
            fold_accuracy = model.score(X_test_fold, Y_test_fold)  # Evaluate on the testing fold
            fold_scores.append(fold_accuracy)

        cv_scores[model_name] = fold_scores
        print(f"{model_name} cross-validation accuracy: {np.mean(fold_scores): .2f}")

    else:
        # Automatic cross-validation for Decision Tree and Random Forest
        scores = cross_val_score(model, X_train_smote, Y_train_smote, cv=5, scoring="accuracy")
        cv_scores[model_name] = scores
        print(f"{model_name} cross-validation accuracy: {np.mean(scores): .2f}")

    print("-" * 70)

cv_scores

"""Random Forest and XGBoost give higher accuracy compared to the Decision Tree with default parameters"""

rfc= RandomForestClassifier(random_state=42)

rfc.fit(X_train_smote, Y_train_smote)

"""**6. Model Evaluation**"""

print(Y_test.value_counts())

# Evaluate on test data

Y_test_pred = model.predict(X_test)

print("Accuracy Score:\n", accuracy_score(Y_test, Y_test_pred))
print("Confusion Matrix:\n", confusion_matrix(Y_test, Y_test_pred))
print("Classification Report:\n", classification_report(Y_test, Y_test_pred))

# save the trained model as a pickle file

model_data = {"model": rfc, "feature_names": X.columns.tolist()}

with open("customer_churn_model.pkl", "wb") as f:
  pickle.dump(model_data, f)

"""**7. Load the saved model and build a Predictive System**"""

# load the saved model and feature names

with open("customer_churn_model.pkl", "rb") as f:
  model_data = pickle.load(f)

loaded_model = model_data["model"]
feature_names = model_data["feature_names"]

print(loaded_model)

print(feature_names)

input_data = {
    'gender': 'Female',
    'SeniorCitizen': 0,
    'Partner': 'Yes',
    'Dependents': 'No',
    'tenure': 1,
    'PhoneService': 'No',
    'MultipleLines': 'No phone service',
    'InternetService': 'DSL',
    'OnlineSecurity': 'No',
    'OnlineBackup': 'Yes',
    'DeviceProtection': 'No',
    'TechSupport': 'No',
    'StreamingTV': 'No',
    'StreamingMovies': 'No',
    'Contract': 'Month-to-month',
    'PaperlessBilling': 'Yes',
    'PaymentMethod': 'Electronic check',
    'MonthlyCharges': 29.85,
    'TotalCharges': 29.85
}


input_data_df = pd.DataFrame([input_data])


with open ("encoders.pkl", "rb") as f:
  encoders = pickle.load(f)



# encode categorical features using the saved encoders

for column, encoder in encoders.items():
  input_data_df[column] = encoder.transform(input_data_df[column])


# make a prediction

prediction = loaded_model.predict(input_data_df)
pred_prob = loaded_model.predict_proba(input_data_df)

print(prediction)

#results

print(f"Prediction: {'Churn' if prediction[0] == 1 else 'No Churn'}")

print(f"Prediction Probability: {pred_prob}")

